PROJECT DOCUMENTATION
Multi-Source Learning Content Ingestion System

1. OVERVIEW
This project is an AI-powered system designed to ingest, process, and query unstructured educational content. It transforms static files (PDFs, Videos, Text) into an interactive knowledge base using Retrieval Augmented Generation (RAG).

2. PROBLEM STATEMENT
Educational data is often fragmented across various formats (video lectures, long PDFs). Searching for specific concepts within these unstructured sources is time-consuming and inefficient.

3. SOLUTION
We built a centralized "Knowledge Hub" that:
- Ingests multiple file types (PDF, MP4, TXT).
- Transcribes video audio to text automatically.
- Indexes content using vector embeddings for semantic search.
- Provides an AI-powered chat interface for querying the data.
- Visualizes the relationships between concepts using a knowledge graph.

4. KEY FEATURES
- Neural Search: Semantic search capabilities that understand user intent beyond keywords.
- Video Intelligence: Integration with OpenAI Whisper to make video content searchable.
- RAG Pipeline: Retrieves relevant context from the vector store to generate accurate, cited answers via LLM (Groq/Llama-3).
- Knowledge Graph: A force-directed graph visualization of connected concepts.

5. TECH STACK
- Frontend: React, Vite, TailwindCSS (Glassmorphism UI)
- Backend: Python, FastAPI
- Database: FAISS (Vector Store)
- AI Models: Llama-3-70B (Groq), all-MiniLM-L6-v2 (Embeddings), Whisper (Audio)

6. USAGE
Users upload documents via the dashboard. The system processes them in the background. Once indexed, users can ask questions in the "Neural Search" page or explore the data in the "Knowledge Universe".

7. FUTURE SCOPE
- Integration with live web sources.
- Multi-language support for transcription and querying.
- Advanced analytics for learning path optimization.
